This directory contains tools for creating content on a set of web
servers, and a client that emulates the behavior of a user-driven
web browser visiting a single web page.

* Creating content

The first step is to gather some content from the web.  The
sample_content/ subdirectory contains a dump of the npr.org home
page, but you can create your own mirror of different sites by
using the make-content.sh script.  It takes a single argument,
which is the url of the web page you want to mirror.  You must
have the wget utility installed, and run it on a host that has
Internet access (n.b. it will not work if you run it on an
experiment node).

* Deploying the content

You will need have at least as many web servers in your experiment
as there are hosts in your content.

The deployment script assumes that the web servers have been
configured via the MAGI apache agent.

Run the 'deploy' command listing which of your experiment nodes
you want to deploy the content to, and the list of machines that
will be acting as web clients.  The web clients must be specified
because the deployment script updates /etc/hosts on those machines
so that the URLs in your web content will be mapped to the
experiment host names.

Note that the deployment script requires the 'lxml' python module.
This module is not currently installed on users.isi.deterlab.net,
so you will need to run the deploy script one one of you
experiment nodes.  The required python module can be installed by
issuing the following command as root:

	# apt-get install python-lxml

The node names can be specified in any way that 'ssh' would
normally understand.  For example, if you are on one of your
experiment nodes, you can use the node's short hostname.  But if
you were invoking the deploy script on users, you would need to
use the fully qualified domain name (e.g. client1.twonodes.safer).

Here's an example of how one might invoke the deploy script:

	$ deploy --clients client1,client2,client3 \
		--servers srv1,srv2,srv3,srv4,srv5,srv6,srv7 \
		--basehost=www.npr.org \
		--contentdir ./sample_content \
		./sample_content/www.npr.org/index.html

* Running a client

The client-fetch.sh script is an example of how to fetch the
content from your experiment web servers.  You can specify the
actual hostname from the Internet, because /etc/hosts gets updated
to map them to the correct experiment node.

* BUGS

- the --client and --server arguments to deploy are listed as
  'optional' in the deploy help message (when invoked with -h),
  even though they are required.  The python argparse module seems
  to have an error where it still lists arguments with
  required=True in the 'optional' section.
